services:
  # Database
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: podcast_ai
      POSTGRES_USER: podcast_user
      POSTGRES_PASSWORD: podcast_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U podcast_user -d podcast_ai"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for Celery
  redis:
    image: redis:7-alpine
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # API Gateway
  api-gateway:
    build: ./services/api-gateway
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Light Reviewer Service
  light-reviewer:
    build: ./services/light-reviewer
    ports:
      - "8007:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama-cpu:11434
      - MODEL_NAME=qwen2:0.5b
      - PORT=8000
      - WORKERS_ACTIVE=1
    depends_on:
      - ollama-cpu
    deploy:
      resources:
        limits:
          cpus: "8"
          memory: "8G"

  # Heavy Reviewer Service
  heavy-reviewer:
    build: ./services/heavy-reviewer
    ports:
      - "8011:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama-cpu:11434
      - MODEL_NAME=qwen2:1.5b
      - PORT=8000
      - WORKERS_ACTIVE=1
    depends_on:
      - ollama-cpu
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: "12G"

  # Reviewer Orchestrator Service
  reviewer:
    build: ./services/reviewer
    ports:
      - "8013:8008"
    environment:
      - PYTHONPATH=/app
      - PORT=8008
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama-cpu:11434
      - LIGHT_REVIEWER_URL=http://light-reviewer:8000
      - HEAVY_REVIEWER_URL=http://heavy-reviewer:8000
      - REVIEWER_CONF_THRESHOLD=0.7
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama-cpu:
        condition: service_started
      light-reviewer:
        condition: service_started
      heavy-reviewer:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Collections Service
  collections:
    build: ./services/collections
    ports:
      - "8014:8011"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - REVIEWER_URL=http://reviewer:8008
      - MIN_FEEDS_PER_COLLECTION=3
      - COLLECTION_TTL_HOURS=24
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      reviewer:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # AI Overseer Service
  ai-overseer:
    build: ./services/ai-overseer
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
      - CELERY_WORKERS=1
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # News Feed Service
  news-feed:
    build: ./services/news-feed
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Text Generation Service
  text-generation:
    build: ./services/text-generation
    ports:
      - "8002:8002"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Writer Service (uses GPU Ollama with gpt-oss-20b for high-quality scripts)
  writer:
    build: ./services/writer
    ports:
      - "8003:8003"
    cpus: "5.0"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen3:latest
      - MAX_TOKENS_PER_REQUEST=5000
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Editor Service
  editor:
    build: ./services/editor
    ports:
      - "8009:8009"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - OLLAMA_BASE_URL=http://ollama-cpu:11434
      - OLLAMA_MODEL=qwen2:1.5b
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      ollama-cpu:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Presenter Service (Persona briefs/feedback using CPU Ollama - NO TTS!)
  presenter:
    build: ./services/presenter
    ports:
      - "8004:8004"
    cpus: "2.0"
    command: uvicorn main:app --host 0.0.0.0 --port 8004 --workers 1
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - OLLAMA_BASE_URL=http://ollama-cpu:11434
      - OLLAMA_MODEL=qwen2:1.5b
      - USE_VIBEVOICE=false
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      ollama-cpu:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # TTS Service (VibeVoice audio generation on GPU - ONLY audio!)
  tts:
    build: ./services/tts
    ports:
      - "8015:8015"
    cpus: "5.0"
    user: "0"
    environment:
      - PYTHONPATH=/app:/app/VibeVoice-Community:/app/services/tts:/app/shared
      - USE_VIBEVOICE=true
      - HF_HOME=/app/.cache/huggingface
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - HF_MODEL_ID=vibevoice/VibeVoice-1.5B
      - AUDIO_STORAGE_PATH=/app/storage
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    runtime: nvidia
    volumes:
      - ./VibeVoice-Community:/app/VibeVoice-Community:ro
      - ./services:/app/services
      - ./shared:/app/shared
      - storage_data:/app/storage
      - hf_cache:/app/.cache/huggingface


  # Publishing Service
  publishing:
    build: ./services/publishing
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - LOCAL_STORAGE_PATH=/app/storage
      - LOCAL_SERVER_URL=http://nginx:8080
      - WORKERS_ACTIVE=1
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nginx:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared
      - storage_data:/app/storage

  # Local Podcast Host Service
  podcast-host:
    build: ./services/podcast-host
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - LOCAL_STORAGE_PATH=/app/storage
      - LOCAL_SERVER_URL=http://nginx:8080
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared
      - storage_data:/app/storage


  # Ollama GPU - For intensive tasks (Writer script generation)
  ollama:
    image: ollama/ollama:latest
    cpus: "4.0"
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_KEEP_ALIVE=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    deploy:
      resources:
        limits:
          cpus: "4.0"
          memory: "12G"
        reservations:
          devices:
            - capabilities: [gpu]
    # Enable NVIDIA GPU for intensive tasks
    runtime: nvidia

  # Ollama CPU - For lighter tasks (Reviewer, Editor)
  ollama-cpu:
    image: ollama/ollama:latest
    cpus: "8.0"
    volumes:
      - ollama_cpu_data:/root/.ollama
    ports:
      - "11435:11434"
    environment:
      - OLLAMA_ORIGINS=*
      - OLLAMA_KEEP_ALIVE=0
      - OLLAMA_NUM_PARALLEL=2
    deploy:
      resources:
        limits:
          cpus: "8.0"
          memory: "8G"

  # Celery Worker
  celery-worker:
    build: ./services/ai-overseer
    command: celery -A app.celery worker --loglevel=info
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Celery Beat (Scheduler)
  celery-beat:
    build: ./services/ai-overseer
    command: celery -A app.celery beat --loglevel=info
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Nginx for static file serving and proxying
  nginx:
    image: nginx:alpine
    ports:
      - "8095:8080"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - storage_data:/app/storage:ro
    depends_on:
      - podcast-host
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
    depends_on:
      - api-gateway
      - reviewer
      - light-reviewer
      - heavy-reviewer

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_INSTALL_PLUGINS=
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus

  # Postgres Exporter for database metrics
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    ports:
      - "9187:9187"
    environment:
      - DATA_SOURCE_NAME=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai?sslmode=disable
    depends_on:
      postgres:
        condition: service_healthy

  # Redis Exporter for cache metrics
  redis-exporter:
    image: oliver006/redis_exporter:latest
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis:6379
    depends_on:
      redis:
        condition: service_healthy

volumes:
  postgres_data:
  ollama_data:
  ollama_cpu_data:
  storage_data:
  hf_cache:
  prometheus_data:
  grafana_data: