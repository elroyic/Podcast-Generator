services:
  # Database
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: podcast_ai
      POSTGRES_USER: podcast_user
      POSTGRES_PASSWORD: podcast_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U podcast_user -d podcast_ai"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for Celery
  redis:
    image: redis:7-alpine
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # API Gateway
  api-gateway:
    build: ./services/api-gateway
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Light Reviewer Service
  light-reviewer:
    build: ./services/light-reviewer
    ports:
      - "8007:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - MODEL_NAME=qwen2:0.5b
      - PORT=8000
    depends_on:
      - ollama
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "4G"

  # Heavy Reviewer Service
  heavy-reviewer:
    build: ./services/heavy-reviewer
    ports:
      - "8011:8000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - MODEL_NAME=qwen3:4b
      - PORT=8000
    depends_on:
      - ollama
    deploy:
      resources:
        limits:
          cpus: "4"
          memory: "12G"

  # Reviewer Orchestrator Service
  reviewer:
    build: ./services/reviewer
    ports:
      - "8013:8008"
    environment:
      - PYTHONPATH=/app
      - PORT=8008
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
      - LIGHT_REVIEWER_URL=http://light-reviewer:8000
      - HEAVY_REVIEWER_URL=http://heavy-reviewer:8000
      - REVIEWER_CONF_THRESHOLD=0.4
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
      light-reviewer:
        condition: service_started
      heavy-reviewer:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Collections Service
  collections:
    build: ./services/collections
    ports:
      - "8014:8011"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - REVIEWER_URL=http://reviewer:8008
      - MIN_FEEDS_PER_COLLECTION=3
      - COLLECTION_TTL_HOURS=24
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      reviewer:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # AI Overseer Service
  ai-overseer:
    build: ./services/ai-overseer
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # News Feed Service
  news-feed:
    build: ./services/news-feed
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Text Generation Service
  text-generation:
    build: ./services/text-generation
    ports:
      - "8002:8002"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Writer Service
  writer:
    build: ./services/writer
    ports:
      - "8003:8003"
    cpus: "5.0"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Editor Service
  editor:
    build: ./services/editor
    ports:
      - "8009:8009"
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Presenter Service
  presenter:
    build: ./services/presenter
    ports:
      - "8004:8004"
    # Allow presenter to use up to 5 CPUs and spawn 5 workers
    cpus: "5.0"
    command: uvicorn main:app --host 0.0.0.0 --port 8004 --workers 5
    user: "0"
    environment:
      - PYTHONPATH=/app:/app/VibeVoice-Community:/app/services/presenter:/app/shared
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - USE_VIBEVOICE=true
      - HF_HOME=/app/.cache/huggingface
      - HF_HUB_ENABLE_HF_TRANSFER=1
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TTS_BACKEND=hf
      - HF_MODEL_ID=aoi-ot/VibeVoice-Large
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    # Enable NVIDIA GPU in Compose (Docker Engine with NVIDIA toolkit)
    runtime: nvidia
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared
      - storage_data:/app/storage
      - hf_cache:/app/.cache/huggingface
      - ./VibeVoice-Community:/app/VibeVoice-Community:ro


  # Publishing Service
  publishing:
    build: ./services/publishing
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - LOCAL_STORAGE_PATH=/app/storage
      - LOCAL_SERVER_URL=http://nginx:8080
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nginx:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared
      - storage_data:/app/storage

  # Local Podcast Host Service
  podcast-host:
    build: ./services/podcast-host
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - LOCAL_STORAGE_PATH=/app/storage
      - LOCAL_SERVER_URL=http://nginx:8080
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared
      - storage_data:/app/storage


  # Ollama for local LLM inference
  ollama:
    image: ollama/ollama:latest
    # Allow Ollama to use up to 5 CPUs
    cpus: "5.0"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_ORIGINS=*
    deploy:
      resources:
        limits:
          cpus: "5.0"
          memory: "8G"

  # Celery Worker
  celery-worker:
    build: ./services/ai-overseer
    command: celery -A app.celery worker --loglevel=info
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Celery Beat (Scheduler)
  celery-beat:
    build: ./services/ai-overseer
    command: celery -A app.celery beat --loglevel=info
    environment:
      - PYTHONPATH=/app
      - DATABASE_URL=postgresql://podcast_user:podcast_pass@postgres:5432/podcast_ai
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ollama:
        condition: service_started
    volumes:
      - ./services:/app/services
      - ./shared:/app/shared

  # Nginx for static file serving and proxying
  nginx:
    image: nginx:alpine
    ports:
      - "8095:8080"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - storage_data:/app/storage:ro
    depends_on:
      - podcast-host
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  postgres_data:
  ollama_data:
  storage_data:
  hf_cache: